{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a web scraper built to scrape job data from indeed.com.\n",
    "\n",
    "The scraper uses selenium webdriver to:\n",
    "    1. Open browser\n",
    "    2. Search for remote positions in data science\n",
    "    3. Pull data fields: job title, company, salary, location, date, job_desc\n",
    "    4. Write data for each role to a jobs list\n",
    "    5. Paginate to next page and repeat process until no more pages left.\n",
    "    6. Write jobs data to a csv (jobs.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import random\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, MWETokenizer\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),options=options) #WebDriver is used to drive a browser (Opens Browser)\n",
    "driver.get(\"https://www.indeed.com\") #this will navigate to the page\n",
    "driver.find_element(\"xpath\", '//*[@id=\"CookiePrivacyNotice\"]/div/button').click()\n",
    "time.sleep(3) #this will suspend execution for 3 seconds\n",
    "driver.find_element(\"xpath\",'//*[@id=\"text-input-what\"]').send_keys(\"Data Science\") #Driver finds the WHAT entry box and inputs the user input variable job_title\n",
    "time.sleep(3)\n",
    "driver.find_element(\"xpath\", '//*[@id=\"text-input-where\"]').send_keys(Keys.CONTROL,\"a\") #Driver finds the where entry box and deletes everything then inputs user input variable location\n",
    "driver.find_element(\"xpath\", '//*[@id=\"text-input-where\"]').send_keys(Keys.DELETE)\n",
    "driver.find_element(\"xpath\",'//*[@id=\"text-input-where\"]').send_keys(\"Remote\")\n",
    "time.sleep(3)\n",
    "driver.find_element(\"xpath\",'/html/body/div').click() #driver finds the element # why is this line necessary?\n",
    "time.sleep(3)\n",
    "try:\n",
    "    driver.find_element(\"xpath\", '//*[@id=\"jobsearch\"]/button').click() #driver tries to find the jobsearch submit button\n",
    "except:\n",
    "    driver.find_element(\"xpath\", '//*[@id=\"whatWhereFormId\"]/div[3]/button').click()\n",
    "time.sleep(2)\n",
    "jobs_list = []\n",
    "links = []\n",
    "current_html = driver.page_source\n",
    "soup = BeautifulSoup(current_html, \"html.parser\")\n",
    "\n",
    "is_element_present = True\n",
    "while is_element_present:\n",
    "    try:\n",
    "        driver.find_element(\"xpath\", '//*[@data-testid=\"pagination-page-next\"]')\n",
    "        for post in soup.select('.job_seen_beacon'):\n",
    "            try:\n",
    "                data = {\n",
    "                    \"job_title\": post.select('.jobTitle')[0].get_text().strip(),\n",
    "                    \"company\": post.select('.companyName')[0].get_text().strip(),\n",
    "                    \"salary\": post.select('.attribute_snippet')[0].get_text().strip(),\n",
    "                    \"location\": post.select('.companyLocation')[0].get_text().strip(),\n",
    "                    \"date\": post.select('.date')[0].get_text().strip(),\n",
    "                    \"links\": post.select('a')[0].get('href')\n",
    "                    }\n",
    "            except IndexError:\n",
    "                continue\n",
    "            jobs_list.append(data)\n",
    "        df=pd.DataFrame(jobs_list)\n",
    "        driver.find_element(\"xpath\", '//*[@data-testid=\"pagination-page-next\"]').click()\n",
    "        time.sleep(random.randint(1, 2))\n",
    "        soup=BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    except NoSuchElementException:\n",
    "        for post in soup.select('.job_seen_beacon'):\n",
    "            try:\n",
    "                data = {\n",
    "                    \"job_title\": post.select('.jobTitle')[0].get_text().strip(),\n",
    "                    \"company\": post.select('.companyName')[0].get_text().strip(),\n",
    "                    \"salary\": post.select('.attribute_snippet')[0].get_text().strip(),\n",
    "                    \"location\": post.select('.companyLocation')[0].get_text().strip(),\n",
    "                    \"date\": post.select('.date')[0].get_text().strip(),\n",
    "                    \"links\": post.select('a')[0].get('href')\n",
    "                    }\n",
    "            except IndexError:\n",
    "                continue\n",
    "            jobs_list.append(data)\n",
    "        df=pd.DataFrame(jobs_list)\n",
    "        break\n",
    "\n",
    "descriptions=[]\n",
    "for link in df.links: \n",
    "    linktosearch = \"https://www.indeed.com\"+link\n",
    "    driver.get(linktosearch)\n",
    "    jd = driver.find_element(\"xpath\",'//div[@id=\"jobDescriptionText\"]').text\n",
    "    descriptions.append(jd)\n",
    "    time.sleep(random.randint(1, 2))\n",
    "\n",
    "df['job_desc'] = descriptions\n",
    "\n",
    "df.to_csv('jobs.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that job listings have been scraped into jobs.csv, we should begin cleaning and exploring our dataset. Check job-data-analysis.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b9eaafb76122de5d1f4409da84f4f35361657e174ed8c81f7f4e55ed0d1132d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
